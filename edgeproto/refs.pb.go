// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: refs.proto

package edgeproto

import proto "github.com/gogo/protobuf/proto"
import fmt "fmt"
import math "math"
import _ "github.com/gogo/googleapis/google/api"
import _ "github.com/mobiledgex/edge-cloud/protogen"
import _ "github.com/mobiledgex/edge-cloud/protoc-gen-cmd/protocmd"
import _ "github.com/gogo/protobuf/gogoproto"

import context "golang.org/x/net/context"
import grpc "google.golang.org/grpc"

import "encoding/json"
import "github.com/mobiledgex/edge-cloud/objstore"
import "github.com/coreos/etcd/clientv3/concurrency"
import "github.com/mobiledgex/edge-cloud/util"
import "github.com/mobiledgex/edge-cloud/log"
import "sort"

import io "io"

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// CloudletRefs track used resources and Clusters instantiated on a Cloudlet. Used resources are compared against max resources for a Cloudlet to determine if resources are available for a new Cluster to be instantiated on the Cloudlet.
type CloudletRefs struct {
	// Cloudlet key
	Key CloudletKey `protobuf:"bytes,1,opt,name=key" json:"key"`
	// Clusters instantiated on the Cloudlet
	Clusters []ClusterKey `protobuf:"bytes,2,rep,name=clusters" json:"clusters"`
	// Used RAM in MB
	UsedRam uint64 `protobuf:"varint,4,opt,name=used_ram,json=usedRam,proto3" json:"used_ram,omitempty"`
	// Used VCPU cores
	UsedVcores uint64 `protobuf:"varint,5,opt,name=used_vcores,json=usedVcores,proto3" json:"used_vcores,omitempty"`
	// Used disk in GB
	UsedDisk uint64 `protobuf:"varint,6,opt,name=used_disk,json=usedDisk,proto3" json:"used_disk,omitempty"`
	// Used ports on root load balancer. Map key is public port, value is unused.
	RootLbPorts map[int32]int32 `protobuf:"bytes,8,rep,name=root_lb_ports,json=rootLbPorts" json:"root_lb_ports,omitempty" protobuf_key:"varint,1,opt,name=key,proto3" protobuf_val:"varint,2,opt,name=value,proto3"`
}

func (m *CloudletRefs) Reset()                    { *m = CloudletRefs{} }
func (m *CloudletRefs) String() string            { return proto.CompactTextString(m) }
func (*CloudletRefs) ProtoMessage()               {}
func (*CloudletRefs) Descriptor() ([]byte, []int) { return fileDescriptorRefs, []int{0} }

// ClusterRefs track used resources within a ClusterInst. Each AppInst specifies a set of required resources (Flavor), so tracking resources used by Apps within a Cluster is necessary to determine if enough resources are available for another AppInst to be instantiated on a ClusterInst.
type ClusterRefs struct {
	// Cluster Instance key
	Key ClusterInstKey `protobuf:"bytes,1,opt,name=key" json:"key"`
	// Apps instances in the Cluster Instance
	Apps []AppKey `protobuf:"bytes,2,rep,name=apps" json:"apps"`
	// Used RAM in MB
	UsedRam uint64 `protobuf:"varint,4,opt,name=used_ram,json=usedRam,proto3" json:"used_ram,omitempty"`
	// Used VCPU cores
	UsedVcores uint64 `protobuf:"varint,5,opt,name=used_vcores,json=usedVcores,proto3" json:"used_vcores,omitempty"`
	// Used disk in GB
	UsedDisk uint64 `protobuf:"varint,6,opt,name=used_disk,json=usedDisk,proto3" json:"used_disk,omitempty"`
}

func (m *ClusterRefs) Reset()                    { *m = ClusterRefs{} }
func (m *ClusterRefs) String() string            { return proto.CompactTextString(m) }
func (*ClusterRefs) ProtoMessage()               {}
func (*ClusterRefs) Descriptor() ([]byte, []int) { return fileDescriptorRefs, []int{1} }

func init() {
	proto.RegisterType((*CloudletRefs)(nil), "edgeproto.CloudletRefs")
	proto.RegisterType((*ClusterRefs)(nil), "edgeproto.ClusterRefs")
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// Client API for CloudletRefsApi service

type CloudletRefsApiClient interface {
	// Show CloudletRefs (debug only)
	ShowCloudletRefs(ctx context.Context, in *CloudletRefs, opts ...grpc.CallOption) (CloudletRefsApi_ShowCloudletRefsClient, error)
}

type cloudletRefsApiClient struct {
	cc *grpc.ClientConn
}

func NewCloudletRefsApiClient(cc *grpc.ClientConn) CloudletRefsApiClient {
	return &cloudletRefsApiClient{cc}
}

func (c *cloudletRefsApiClient) ShowCloudletRefs(ctx context.Context, in *CloudletRefs, opts ...grpc.CallOption) (CloudletRefsApi_ShowCloudletRefsClient, error) {
	stream, err := grpc.NewClientStream(ctx, &_CloudletRefsApi_serviceDesc.Streams[0], c.cc, "/edgeproto.CloudletRefsApi/ShowCloudletRefs", opts...)
	if err != nil {
		return nil, err
	}
	x := &cloudletRefsApiShowCloudletRefsClient{stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type CloudletRefsApi_ShowCloudletRefsClient interface {
	Recv() (*CloudletRefs, error)
	grpc.ClientStream
}

type cloudletRefsApiShowCloudletRefsClient struct {
	grpc.ClientStream
}

func (x *cloudletRefsApiShowCloudletRefsClient) Recv() (*CloudletRefs, error) {
	m := new(CloudletRefs)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

// Server API for CloudletRefsApi service

type CloudletRefsApiServer interface {
	// Show CloudletRefs (debug only)
	ShowCloudletRefs(*CloudletRefs, CloudletRefsApi_ShowCloudletRefsServer) error
}

func RegisterCloudletRefsApiServer(s *grpc.Server, srv CloudletRefsApiServer) {
	s.RegisterService(&_CloudletRefsApi_serviceDesc, srv)
}

func _CloudletRefsApi_ShowCloudletRefs_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(CloudletRefs)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(CloudletRefsApiServer).ShowCloudletRefs(m, &cloudletRefsApiShowCloudletRefsServer{stream})
}

type CloudletRefsApi_ShowCloudletRefsServer interface {
	Send(*CloudletRefs) error
	grpc.ServerStream
}

type cloudletRefsApiShowCloudletRefsServer struct {
	grpc.ServerStream
}

func (x *cloudletRefsApiShowCloudletRefsServer) Send(m *CloudletRefs) error {
	return x.ServerStream.SendMsg(m)
}

var _CloudletRefsApi_serviceDesc = grpc.ServiceDesc{
	ServiceName: "edgeproto.CloudletRefsApi",
	HandlerType: (*CloudletRefsApiServer)(nil),
	Methods:     []grpc.MethodDesc{},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "ShowCloudletRefs",
			Handler:       _CloudletRefsApi_ShowCloudletRefs_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "refs.proto",
}

// Client API for ClusterRefsApi service

type ClusterRefsApiClient interface {
	// Show ClusterRefs (debug only)
	ShowClusterRefs(ctx context.Context, in *ClusterRefs, opts ...grpc.CallOption) (ClusterRefsApi_ShowClusterRefsClient, error)
}

type clusterRefsApiClient struct {
	cc *grpc.ClientConn
}

func NewClusterRefsApiClient(cc *grpc.ClientConn) ClusterRefsApiClient {
	return &clusterRefsApiClient{cc}
}

func (c *clusterRefsApiClient) ShowClusterRefs(ctx context.Context, in *ClusterRefs, opts ...grpc.CallOption) (ClusterRefsApi_ShowClusterRefsClient, error) {
	stream, err := grpc.NewClientStream(ctx, &_ClusterRefsApi_serviceDesc.Streams[0], c.cc, "/edgeproto.ClusterRefsApi/ShowClusterRefs", opts...)
	if err != nil {
		return nil, err
	}
	x := &clusterRefsApiShowClusterRefsClient{stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type ClusterRefsApi_ShowClusterRefsClient interface {
	Recv() (*ClusterRefs, error)
	grpc.ClientStream
}

type clusterRefsApiShowClusterRefsClient struct {
	grpc.ClientStream
}

func (x *clusterRefsApiShowClusterRefsClient) Recv() (*ClusterRefs, error) {
	m := new(ClusterRefs)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

// Server API for ClusterRefsApi service

type ClusterRefsApiServer interface {
	// Show ClusterRefs (debug only)
	ShowClusterRefs(*ClusterRefs, ClusterRefsApi_ShowClusterRefsServer) error
}

func RegisterClusterRefsApiServer(s *grpc.Server, srv ClusterRefsApiServer) {
	s.RegisterService(&_ClusterRefsApi_serviceDesc, srv)
}

func _ClusterRefsApi_ShowClusterRefs_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(ClusterRefs)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(ClusterRefsApiServer).ShowClusterRefs(m, &clusterRefsApiShowClusterRefsServer{stream})
}

type ClusterRefsApi_ShowClusterRefsServer interface {
	Send(*ClusterRefs) error
	grpc.ServerStream
}

type clusterRefsApiShowClusterRefsServer struct {
	grpc.ServerStream
}

func (x *clusterRefsApiShowClusterRefsServer) Send(m *ClusterRefs) error {
	return x.ServerStream.SendMsg(m)
}

var _ClusterRefsApi_serviceDesc = grpc.ServiceDesc{
	ServiceName: "edgeproto.ClusterRefsApi",
	HandlerType: (*ClusterRefsApiServer)(nil),
	Methods:     []grpc.MethodDesc{},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "ShowClusterRefs",
			Handler:       _ClusterRefsApi_ShowClusterRefs_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "refs.proto",
}

func (m *CloudletRefs) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *CloudletRefs) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintRefs(dAtA, i, uint64(m.Key.Size()))
	n1, err := m.Key.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n1
	if len(m.Clusters) > 0 {
		for _, msg := range m.Clusters {
			dAtA[i] = 0x12
			i++
			i = encodeVarintRefs(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if m.UsedRam != 0 {
		dAtA[i] = 0x20
		i++
		i = encodeVarintRefs(dAtA, i, uint64(m.UsedRam))
	}
	if m.UsedVcores != 0 {
		dAtA[i] = 0x28
		i++
		i = encodeVarintRefs(dAtA, i, uint64(m.UsedVcores))
	}
	if m.UsedDisk != 0 {
		dAtA[i] = 0x30
		i++
		i = encodeVarintRefs(dAtA, i, uint64(m.UsedDisk))
	}
	if len(m.RootLbPorts) > 0 {
		for k, _ := range m.RootLbPorts {
			dAtA[i] = 0x42
			i++
			v := m.RootLbPorts[k]
			mapSize := 1 + sovRefs(uint64(k)) + 1 + sovRefs(uint64(v))
			i = encodeVarintRefs(dAtA, i, uint64(mapSize))
			dAtA[i] = 0x8
			i++
			i = encodeVarintRefs(dAtA, i, uint64(k))
			dAtA[i] = 0x10
			i++
			i = encodeVarintRefs(dAtA, i, uint64(v))
		}
	}
	return i, nil
}

func (m *ClusterRefs) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ClusterRefs) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintRefs(dAtA, i, uint64(m.Key.Size()))
	n2, err := m.Key.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n2
	if len(m.Apps) > 0 {
		for _, msg := range m.Apps {
			dAtA[i] = 0x12
			i++
			i = encodeVarintRefs(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if m.UsedRam != 0 {
		dAtA[i] = 0x20
		i++
		i = encodeVarintRefs(dAtA, i, uint64(m.UsedRam))
	}
	if m.UsedVcores != 0 {
		dAtA[i] = 0x28
		i++
		i = encodeVarintRefs(dAtA, i, uint64(m.UsedVcores))
	}
	if m.UsedDisk != 0 {
		dAtA[i] = 0x30
		i++
		i = encodeVarintRefs(dAtA, i, uint64(m.UsedDisk))
	}
	return i, nil
}

func encodeVarintRefs(dAtA []byte, offset int, v uint64) int {
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return offset + 1
}
func (m *CloudletRefs) Matches(o *CloudletRefs, fopts ...MatchOpt) bool {
	opts := MatchOptions{}
	applyMatchOptions(&opts, fopts...)
	if o == nil {
		if opts.Filter {
			return true
		}
		return false
	}
	if !m.Key.Matches(&o.Key, fopts...) {
		return false
	}
	if !opts.Filter || o.Clusters != nil {
		if m.Clusters == nil && o.Clusters != nil || m.Clusters != nil && o.Clusters == nil {
			return false
		} else if m.Clusters != nil && o.Clusters != nil {
			if len(m.Clusters) != len(o.Clusters) {
				return false
			}
			if opts.SortArrayedKeys {
				sort.Slice(m.Clusters, func(i, j int) bool {
					return m.Clusters[i].GetKeyString() < m.Clusters[j].GetKeyString()
				})
				sort.Slice(o.Clusters, func(i, j int) bool {
					return o.Clusters[i].GetKeyString() < o.Clusters[j].GetKeyString()
				})
			}
			for i := 0; i < len(m.Clusters); i++ {
				if !m.Clusters[i].Matches(&o.Clusters[i], fopts...) {
					return false
				}
			}
		}
	}
	if !opts.Filter || o.UsedRam != 0 {
		if o.UsedRam != m.UsedRam {
			return false
		}
	}
	if !opts.Filter || o.UsedVcores != 0 {
		if o.UsedVcores != m.UsedVcores {
			return false
		}
	}
	if !opts.Filter || o.UsedDisk != 0 {
		if o.UsedDisk != m.UsedDisk {
			return false
		}
	}
	if !opts.Filter || o.RootLbPorts != nil {
		if m.RootLbPorts == nil && o.RootLbPorts != nil || m.RootLbPorts != nil && o.RootLbPorts == nil {
			return false
		} else if m.RootLbPorts != nil && o.RootLbPorts != nil {
			if len(m.RootLbPorts) != len(o.RootLbPorts) {
				return false
			}
			for k, _ := range m.RootLbPorts {
				_, ok := o.RootLbPorts[k]
				if !ok {
					return false
				}
				if o.RootLbPorts[k] != m.RootLbPorts[k] {
					return false
				}
			}
		}
	}
	return true
}

func (m *CloudletRefs) CopyInFields(src *CloudletRefs) {
	m.Key.OperatorKey.Name = src.Key.OperatorKey.Name
	m.Key.Name = src.Key.Name
	if m.Clusters == nil || len(m.Clusters) != len(src.Clusters) {
		m.Clusters = make([]ClusterKey, len(src.Clusters))
	}
	for i0 := 0; i0 < len(src.Clusters); i0++ {
		m.Clusters[i0].Name = src.Clusters[i0].Name
	}
	m.UsedRam = src.UsedRam
	m.UsedVcores = src.UsedVcores
	m.UsedDisk = src.UsedDisk
	if src.RootLbPorts != nil {
		m.RootLbPorts = make(map[int32]int32)
		for k0, _ := range src.RootLbPorts {
			m.RootLbPorts[k0] = src.RootLbPorts[k0]
		}
	}
}

func (s *CloudletRefs) HasFields() bool {
	return false
}

type CloudletRefsStore struct {
	kvstore objstore.KVStore
}

func NewCloudletRefsStore(kvstore objstore.KVStore) CloudletRefsStore {
	return CloudletRefsStore{kvstore: kvstore}
}

func (s *CloudletRefsStore) Create(m *CloudletRefs, wait func(int64)) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("CloudletRefs", m.GetKey())
	val, err := json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Create(key, string(val))
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *CloudletRefsStore) Update(m *CloudletRefs, wait func(int64)) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("CloudletRefs", m.GetKey())
	var vers int64 = 0
	val, err := json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Update(key, string(val), vers)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *CloudletRefsStore) Put(m *CloudletRefs, wait func(int64)) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("CloudletRefs", m.GetKey())
	var val []byte
	val, err = json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Put(key, string(val))
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *CloudletRefsStore) Delete(m *CloudletRefs, wait func(int64)) (*Result, error) {
	err := m.GetKey().Validate()
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("CloudletRefs", m.GetKey())
	rev, err := s.kvstore.Delete(key)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *CloudletRefsStore) LoadOne(key string) (*CloudletRefs, int64, error) {
	val, rev, _, err := s.kvstore.Get(key)
	if err != nil {
		return nil, 0, err
	}
	var obj CloudletRefs
	err = json.Unmarshal(val, &obj)
	if err != nil {
		log.DebugLog(log.DebugLevelApi, "Failed to parse CloudletRefs data", "val", string(val))
		return nil, 0, err
	}
	return &obj, rev, nil
}

func (s *CloudletRefsStore) STMGet(stm concurrency.STM, key *CloudletKey, buf *CloudletRefs) bool {
	keystr := objstore.DbKeyString("CloudletRefs", key)
	valstr := stm.Get(keystr)
	if valstr == "" {
		return false
	}
	if buf != nil {
		err := json.Unmarshal([]byte(valstr), buf)
		if err != nil {
			return false
		}
	}
	return true
}

func (s *CloudletRefsStore) STMPut(stm concurrency.STM, obj *CloudletRefs) {
	keystr := objstore.DbKeyString("CloudletRefs", obj.GetKey())
	val, _ := json.Marshal(obj)
	stm.Put(keystr, string(val))
}

func (s *CloudletRefsStore) STMDel(stm concurrency.STM, key *CloudletKey) {
	keystr := objstore.DbKeyString("CloudletRefs", key)
	stm.Del(keystr)
}

type CloudletRefsKeyWatcher struct {
	cb func()
}

// CloudletRefsCache caches CloudletRefs objects in memory in a hash table
// and keeps them in sync with the database.
type CloudletRefsCache struct {
	Objs        map[CloudletKey]*CloudletRefs
	Mux         util.Mutex
	List        map[CloudletKey]struct{}
	NotifyCb    func(obj *CloudletKey, old *CloudletRefs)
	UpdatedCb   func(old *CloudletRefs, new *CloudletRefs)
	KeyWatchers map[CloudletKey][]*CloudletRefsKeyWatcher
}

func NewCloudletRefsCache() *CloudletRefsCache {
	cache := CloudletRefsCache{}
	InitCloudletRefsCache(&cache)
	return &cache
}

func InitCloudletRefsCache(cache *CloudletRefsCache) {
	cache.Objs = make(map[CloudletKey]*CloudletRefs)
	cache.KeyWatchers = make(map[CloudletKey][]*CloudletRefsKeyWatcher)
}

func (c *CloudletRefsCache) GetTypeString() string {
	return "CloudletRefs"
}

func (c *CloudletRefsCache) Get(key *CloudletKey, valbuf *CloudletRefs) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	inst, found := c.Objs[*key]
	if found {
		*valbuf = *inst
	}
	return found
}

func (c *CloudletRefsCache) HasKey(key *CloudletKey) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	_, found := c.Objs[*key]
	return found
}

func (c *CloudletRefsCache) GetAllKeys(keys map[CloudletKey]struct{}) {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for key, _ := range c.Objs {
		keys[key] = struct{}{}
	}
}

func (c *CloudletRefsCache) Update(in *CloudletRefs, rev int64) {
	c.Mux.Lock()
	if c.UpdatedCb != nil || c.NotifyCb != nil {
		old := c.Objs[in.Key]
		if c.UpdatedCb != nil {
			new := &CloudletRefs{}
			*new = *in
			defer c.UpdatedCb(old, new)
		}
		if c.NotifyCb != nil {
			defer c.NotifyCb(&in.Key, old)
		}
	}
	c.Objs[in.Key] = in
	log.DebugLog(log.DebugLevelApi, "SyncUpdate CloudletRefs", "obj", in, "rev", rev)
	c.Mux.Unlock()
	c.TriggerKeyWatchers(&in.Key)
}

func (c *CloudletRefsCache) Delete(in *CloudletRefs, rev int64) {
	c.Mux.Lock()
	old := c.Objs[in.Key]
	delete(c.Objs, in.Key)
	log.DebugLog(log.DebugLevelApi, "SyncDelete CloudletRefs", "key", in.Key, "rev", rev)
	c.Mux.Unlock()
	if c.NotifyCb != nil {
		c.NotifyCb(&in.Key, old)
	}
	c.TriggerKeyWatchers(&in.Key)
}

func (c *CloudletRefsCache) Prune(validKeys map[CloudletKey]struct{}) {
	notify := make(map[CloudletKey]*CloudletRefs)
	c.Mux.Lock()
	for key, _ := range c.Objs {
		if _, ok := validKeys[key]; !ok {
			if c.NotifyCb != nil {
				notify[key] = c.Objs[key]
			}
			delete(c.Objs, key)
		}
	}
	c.Mux.Unlock()
	for key, old := range notify {
		if c.NotifyCb != nil {
			c.NotifyCb(&key, old)
		}
		c.TriggerKeyWatchers(&key)
	}
}

func (c *CloudletRefsCache) GetCount() int {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	return len(c.Objs)
}

func (c *CloudletRefsCache) Show(filter *CloudletRefs, cb func(ret *CloudletRefs) error) error {
	log.DebugLog(log.DebugLevelApi, "Show CloudletRefs", "count", len(c.Objs))
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for _, obj := range c.Objs {
		if !obj.Matches(filter, MatchFilter()) {
			continue
		}
		log.DebugLog(log.DebugLevelApi, "Show CloudletRefs", "obj", obj)
		err := cb(obj)
		if err != nil {
			return err
		}
	}
	return nil
}

func (c *CloudletRefsCache) SetNotifyCb(fn func(obj *CloudletKey, old *CloudletRefs)) {
	c.NotifyCb = fn
}

func (c *CloudletRefsCache) SetUpdatedCb(fn func(old *CloudletRefs, new *CloudletRefs)) {
	c.UpdatedCb = fn
}

func (c *CloudletRefsCache) WatchKey(key *CloudletKey, cb func()) context.CancelFunc {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	list, ok := c.KeyWatchers[*key]
	if !ok {
		list = make([]*CloudletRefsKeyWatcher, 0)
	}
	watcher := CloudletRefsKeyWatcher{cb: cb}
	c.KeyWatchers[*key] = append(list, &watcher)
	log.DebugLog(log.DebugLevelApi, "Watching CloudletRefs", "key", key)
	return func() {
		c.Mux.Lock()
		defer c.Mux.Unlock()
		list, ok := c.KeyWatchers[*key]
		if !ok {
			return
		}
		for ii, _ := range list {
			if list[ii] != &watcher {
				continue
			}
			if len(list) == 1 {
				delete(c.KeyWatchers, *key)
				return
			}
			list[ii] = list[len(list)-1]
			list[len(list)-1] = nil
			c.KeyWatchers[*key] = list[:len(list)-1]
			return
		}
	}
}

func (c *CloudletRefsCache) TriggerKeyWatchers(key *CloudletKey) {
	watchers := make([]*CloudletRefsKeyWatcher, 0)
	c.Mux.Lock()
	if list, ok := c.KeyWatchers[*key]; ok {
		watchers = append(watchers, list...)
	}
	c.Mux.Unlock()
	for ii, _ := range watchers {
		watchers[ii].cb()
	}
}
func (c *CloudletRefsCache) SyncUpdate(key, val []byte, rev int64) {
	obj := CloudletRefs{}
	err := json.Unmarshal(val, &obj)
	if err != nil {
		log.WarnLog("Failed to parse CloudletRefs data", "val", string(val))
		return
	}
	c.Update(&obj, rev)
	c.Mux.Lock()
	if c.List != nil {
		c.List[obj.Key] = struct{}{}
	}
	c.Mux.Unlock()
}

func (c *CloudletRefsCache) SyncDelete(key []byte, rev int64) {
	obj := CloudletRefs{}
	keystr := objstore.DbKeyPrefixRemove(string(key))
	CloudletKeyStringParse(keystr, &obj.Key)
	c.Delete(&obj, rev)
}

func (c *CloudletRefsCache) SyncListStart() {
	c.List = make(map[CloudletKey]struct{})
}

func (c *CloudletRefsCache) SyncListEnd() {
	deleted := make(map[CloudletKey]*CloudletRefs)
	c.Mux.Lock()
	for key, val := range c.Objs {
		if _, found := c.List[key]; !found {
			deleted[key] = val
			delete(c.Objs, key)
		}
	}
	c.List = nil
	c.Mux.Unlock()
	if c.NotifyCb != nil {
		for key, val := range deleted {
			c.NotifyCb(&key, val)
			c.TriggerKeyWatchers(&key)
		}
	}
}

func (m *CloudletRefs) GetKey() *CloudletKey {
	return &m.Key
}

func (m *ClusterRefs) Matches(o *ClusterRefs, fopts ...MatchOpt) bool {
	opts := MatchOptions{}
	applyMatchOptions(&opts, fopts...)
	if o == nil {
		if opts.Filter {
			return true
		}
		return false
	}
	if !m.Key.Matches(&o.Key, fopts...) {
		return false
	}
	if !opts.Filter || o.Apps != nil {
		if m.Apps == nil && o.Apps != nil || m.Apps != nil && o.Apps == nil {
			return false
		} else if m.Apps != nil && o.Apps != nil {
			if len(m.Apps) != len(o.Apps) {
				return false
			}
			if opts.SortArrayedKeys {
				sort.Slice(m.Apps, func(i, j int) bool {
					return m.Apps[i].GetKeyString() < m.Apps[j].GetKeyString()
				})
				sort.Slice(o.Apps, func(i, j int) bool {
					return o.Apps[i].GetKeyString() < o.Apps[j].GetKeyString()
				})
			}
			for i := 0; i < len(m.Apps); i++ {
				if !m.Apps[i].Matches(&o.Apps[i], fopts...) {
					return false
				}
			}
		}
	}
	if !opts.Filter || o.UsedRam != 0 {
		if o.UsedRam != m.UsedRam {
			return false
		}
	}
	if !opts.Filter || o.UsedVcores != 0 {
		if o.UsedVcores != m.UsedVcores {
			return false
		}
	}
	if !opts.Filter || o.UsedDisk != 0 {
		if o.UsedDisk != m.UsedDisk {
			return false
		}
	}
	return true
}

func (m *ClusterRefs) CopyInFields(src *ClusterRefs) {
	m.Key.ClusterKey.Name = src.Key.ClusterKey.Name
	m.Key.CloudletKey.OperatorKey.Name = src.Key.CloudletKey.OperatorKey.Name
	m.Key.CloudletKey.Name = src.Key.CloudletKey.Name
	if m.Apps == nil || len(m.Apps) != len(src.Apps) {
		m.Apps = make([]AppKey, len(src.Apps))
	}
	for i0 := 0; i0 < len(src.Apps); i0++ {
		m.Apps[i0].DeveloperKey.Name = src.Apps[i0].DeveloperKey.Name
		m.Apps[i0].Name = src.Apps[i0].Name
		m.Apps[i0].Version = src.Apps[i0].Version
	}
	m.UsedRam = src.UsedRam
	m.UsedVcores = src.UsedVcores
	m.UsedDisk = src.UsedDisk
}

func (s *ClusterRefs) HasFields() bool {
	return false
}

type ClusterRefsStore struct {
	kvstore objstore.KVStore
}

func NewClusterRefsStore(kvstore objstore.KVStore) ClusterRefsStore {
	return ClusterRefsStore{kvstore: kvstore}
}

func (s *ClusterRefsStore) Create(m *ClusterRefs, wait func(int64)) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("ClusterRefs", m.GetKey())
	val, err := json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Create(key, string(val))
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *ClusterRefsStore) Update(m *ClusterRefs, wait func(int64)) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("ClusterRefs", m.GetKey())
	var vers int64 = 0
	val, err := json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Update(key, string(val), vers)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *ClusterRefsStore) Put(m *ClusterRefs, wait func(int64)) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("ClusterRefs", m.GetKey())
	var val []byte
	val, err = json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Put(key, string(val))
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *ClusterRefsStore) Delete(m *ClusterRefs, wait func(int64)) (*Result, error) {
	err := m.GetKey().Validate()
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("ClusterRefs", m.GetKey())
	rev, err := s.kvstore.Delete(key)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *ClusterRefsStore) LoadOne(key string) (*ClusterRefs, int64, error) {
	val, rev, _, err := s.kvstore.Get(key)
	if err != nil {
		return nil, 0, err
	}
	var obj ClusterRefs
	err = json.Unmarshal(val, &obj)
	if err != nil {
		log.DebugLog(log.DebugLevelApi, "Failed to parse ClusterRefs data", "val", string(val))
		return nil, 0, err
	}
	return &obj, rev, nil
}

func (s *ClusterRefsStore) STMGet(stm concurrency.STM, key *ClusterInstKey, buf *ClusterRefs) bool {
	keystr := objstore.DbKeyString("ClusterRefs", key)
	valstr := stm.Get(keystr)
	if valstr == "" {
		return false
	}
	if buf != nil {
		err := json.Unmarshal([]byte(valstr), buf)
		if err != nil {
			return false
		}
	}
	return true
}

func (s *ClusterRefsStore) STMPut(stm concurrency.STM, obj *ClusterRefs) {
	keystr := objstore.DbKeyString("ClusterRefs", obj.GetKey())
	val, _ := json.Marshal(obj)
	stm.Put(keystr, string(val))
}

func (s *ClusterRefsStore) STMDel(stm concurrency.STM, key *ClusterInstKey) {
	keystr := objstore.DbKeyString("ClusterRefs", key)
	stm.Del(keystr)
}

type ClusterRefsKeyWatcher struct {
	cb func()
}

// ClusterRefsCache caches ClusterRefs objects in memory in a hash table
// and keeps them in sync with the database.
type ClusterRefsCache struct {
	Objs        map[ClusterInstKey]*ClusterRefs
	Mux         util.Mutex
	List        map[ClusterInstKey]struct{}
	NotifyCb    func(obj *ClusterInstKey, old *ClusterRefs)
	UpdatedCb   func(old *ClusterRefs, new *ClusterRefs)
	KeyWatchers map[ClusterInstKey][]*ClusterRefsKeyWatcher
}

func NewClusterRefsCache() *ClusterRefsCache {
	cache := ClusterRefsCache{}
	InitClusterRefsCache(&cache)
	return &cache
}

func InitClusterRefsCache(cache *ClusterRefsCache) {
	cache.Objs = make(map[ClusterInstKey]*ClusterRefs)
	cache.KeyWatchers = make(map[ClusterInstKey][]*ClusterRefsKeyWatcher)
}

func (c *ClusterRefsCache) GetTypeString() string {
	return "ClusterRefs"
}

func (c *ClusterRefsCache) Get(key *ClusterInstKey, valbuf *ClusterRefs) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	inst, found := c.Objs[*key]
	if found {
		*valbuf = *inst
	}
	return found
}

func (c *ClusterRefsCache) HasKey(key *ClusterInstKey) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	_, found := c.Objs[*key]
	return found
}

func (c *ClusterRefsCache) GetAllKeys(keys map[ClusterInstKey]struct{}) {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for key, _ := range c.Objs {
		keys[key] = struct{}{}
	}
}

func (c *ClusterRefsCache) Update(in *ClusterRefs, rev int64) {
	c.Mux.Lock()
	if c.UpdatedCb != nil || c.NotifyCb != nil {
		old := c.Objs[in.Key]
		if c.UpdatedCb != nil {
			new := &ClusterRefs{}
			*new = *in
			defer c.UpdatedCb(old, new)
		}
		if c.NotifyCb != nil {
			defer c.NotifyCb(&in.Key, old)
		}
	}
	c.Objs[in.Key] = in
	log.DebugLog(log.DebugLevelApi, "SyncUpdate ClusterRefs", "obj", in, "rev", rev)
	c.Mux.Unlock()
	c.TriggerKeyWatchers(&in.Key)
}

func (c *ClusterRefsCache) Delete(in *ClusterRefs, rev int64) {
	c.Mux.Lock()
	old := c.Objs[in.Key]
	delete(c.Objs, in.Key)
	log.DebugLog(log.DebugLevelApi, "SyncDelete ClusterRefs", "key", in.Key, "rev", rev)
	c.Mux.Unlock()
	if c.NotifyCb != nil {
		c.NotifyCb(&in.Key, old)
	}
	c.TriggerKeyWatchers(&in.Key)
}

func (c *ClusterRefsCache) Prune(validKeys map[ClusterInstKey]struct{}) {
	notify := make(map[ClusterInstKey]*ClusterRefs)
	c.Mux.Lock()
	for key, _ := range c.Objs {
		if _, ok := validKeys[key]; !ok {
			if c.NotifyCb != nil {
				notify[key] = c.Objs[key]
			}
			delete(c.Objs, key)
		}
	}
	c.Mux.Unlock()
	for key, old := range notify {
		if c.NotifyCb != nil {
			c.NotifyCb(&key, old)
		}
		c.TriggerKeyWatchers(&key)
	}
}

func (c *ClusterRefsCache) GetCount() int {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	return len(c.Objs)
}

func (c *ClusterRefsCache) Show(filter *ClusterRefs, cb func(ret *ClusterRefs) error) error {
	log.DebugLog(log.DebugLevelApi, "Show ClusterRefs", "count", len(c.Objs))
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for _, obj := range c.Objs {
		if !obj.Matches(filter, MatchFilter()) {
			continue
		}
		log.DebugLog(log.DebugLevelApi, "Show ClusterRefs", "obj", obj)
		err := cb(obj)
		if err != nil {
			return err
		}
	}
	return nil
}

func (c *ClusterRefsCache) SetNotifyCb(fn func(obj *ClusterInstKey, old *ClusterRefs)) {
	c.NotifyCb = fn
}

func (c *ClusterRefsCache) SetUpdatedCb(fn func(old *ClusterRefs, new *ClusterRefs)) {
	c.UpdatedCb = fn
}

func (c *ClusterRefsCache) WatchKey(key *ClusterInstKey, cb func()) context.CancelFunc {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	list, ok := c.KeyWatchers[*key]
	if !ok {
		list = make([]*ClusterRefsKeyWatcher, 0)
	}
	watcher := ClusterRefsKeyWatcher{cb: cb}
	c.KeyWatchers[*key] = append(list, &watcher)
	log.DebugLog(log.DebugLevelApi, "Watching ClusterRefs", "key", key)
	return func() {
		c.Mux.Lock()
		defer c.Mux.Unlock()
		list, ok := c.KeyWatchers[*key]
		if !ok {
			return
		}
		for ii, _ := range list {
			if list[ii] != &watcher {
				continue
			}
			if len(list) == 1 {
				delete(c.KeyWatchers, *key)
				return
			}
			list[ii] = list[len(list)-1]
			list[len(list)-1] = nil
			c.KeyWatchers[*key] = list[:len(list)-1]
			return
		}
	}
}

func (c *ClusterRefsCache) TriggerKeyWatchers(key *ClusterInstKey) {
	watchers := make([]*ClusterRefsKeyWatcher, 0)
	c.Mux.Lock()
	if list, ok := c.KeyWatchers[*key]; ok {
		watchers = append(watchers, list...)
	}
	c.Mux.Unlock()
	for ii, _ := range watchers {
		watchers[ii].cb()
	}
}
func (c *ClusterRefsCache) SyncUpdate(key, val []byte, rev int64) {
	obj := ClusterRefs{}
	err := json.Unmarshal(val, &obj)
	if err != nil {
		log.WarnLog("Failed to parse ClusterRefs data", "val", string(val))
		return
	}
	c.Update(&obj, rev)
	c.Mux.Lock()
	if c.List != nil {
		c.List[obj.Key] = struct{}{}
	}
	c.Mux.Unlock()
}

func (c *ClusterRefsCache) SyncDelete(key []byte, rev int64) {
	obj := ClusterRefs{}
	keystr := objstore.DbKeyPrefixRemove(string(key))
	ClusterInstKeyStringParse(keystr, &obj.Key)
	c.Delete(&obj, rev)
}

func (c *ClusterRefsCache) SyncListStart() {
	c.List = make(map[ClusterInstKey]struct{})
}

func (c *ClusterRefsCache) SyncListEnd() {
	deleted := make(map[ClusterInstKey]*ClusterRefs)
	c.Mux.Lock()
	for key, val := range c.Objs {
		if _, found := c.List[key]; !found {
			deleted[key] = val
			delete(c.Objs, key)
		}
	}
	c.List = nil
	c.Mux.Unlock()
	if c.NotifyCb != nil {
		for key, val := range deleted {
			c.NotifyCb(&key, val)
			c.TriggerKeyWatchers(&key)
		}
	}
}

func (m *ClusterRefs) GetKey() *ClusterInstKey {
	return &m.Key
}

func (m *CloudletRefs) Size() (n int) {
	var l int
	_ = l
	l = m.Key.Size()
	n += 1 + l + sovRefs(uint64(l))
	if len(m.Clusters) > 0 {
		for _, e := range m.Clusters {
			l = e.Size()
			n += 1 + l + sovRefs(uint64(l))
		}
	}
	if m.UsedRam != 0 {
		n += 1 + sovRefs(uint64(m.UsedRam))
	}
	if m.UsedVcores != 0 {
		n += 1 + sovRefs(uint64(m.UsedVcores))
	}
	if m.UsedDisk != 0 {
		n += 1 + sovRefs(uint64(m.UsedDisk))
	}
	if len(m.RootLbPorts) > 0 {
		for k, v := range m.RootLbPorts {
			_ = k
			_ = v
			mapEntrySize := 1 + sovRefs(uint64(k)) + 1 + sovRefs(uint64(v))
			n += mapEntrySize + 1 + sovRefs(uint64(mapEntrySize))
		}
	}
	return n
}

func (m *ClusterRefs) Size() (n int) {
	var l int
	_ = l
	l = m.Key.Size()
	n += 1 + l + sovRefs(uint64(l))
	if len(m.Apps) > 0 {
		for _, e := range m.Apps {
			l = e.Size()
			n += 1 + l + sovRefs(uint64(l))
		}
	}
	if m.UsedRam != 0 {
		n += 1 + sovRefs(uint64(m.UsedRam))
	}
	if m.UsedVcores != 0 {
		n += 1 + sovRefs(uint64(m.UsedVcores))
	}
	if m.UsedDisk != 0 {
		n += 1 + sovRefs(uint64(m.UsedDisk))
	}
	return n
}

func sovRefs(x uint64) (n int) {
	for {
		n++
		x >>= 7
		if x == 0 {
			break
		}
	}
	return n
}
func sozRefs(x uint64) (n int) {
	return sovRefs(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (m *CloudletRefs) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowRefs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: CloudletRefs: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: CloudletRefs: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Key.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Clusters", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Clusters = append(m.Clusters, ClusterKey{})
			if err := m.Clusters[len(m.Clusters)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UsedRam", wireType)
			}
			m.UsedRam = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.UsedRam |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UsedVcores", wireType)
			}
			m.UsedVcores = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.UsedVcores |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UsedDisk", wireType)
			}
			m.UsedDisk = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.UsedDisk |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RootLbPorts", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.RootLbPorts == nil {
				m.RootLbPorts = make(map[int32]int32)
			}
			var mapkey int32
			var mapvalue int32
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowRefs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowRefs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapkey |= (int32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else if fieldNum == 2 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowRefs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapvalue |= (int32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipRefs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if skippy < 0 {
						return ErrInvalidLengthRefs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.RootLbPorts[mapkey] = mapvalue
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipRefs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthRefs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ClusterRefs) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowRefs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ClusterRefs: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ClusterRefs: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Key.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Apps", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Apps = append(m.Apps, AppKey{})
			if err := m.Apps[len(m.Apps)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UsedRam", wireType)
			}
			m.UsedRam = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.UsedRam |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UsedVcores", wireType)
			}
			m.UsedVcores = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.UsedVcores |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UsedDisk", wireType)
			}
			m.UsedDisk = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.UsedDisk |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipRefs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthRefs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipRefs(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowRefs
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
			return iNdEx, nil
		case 1:
			iNdEx += 8
			return iNdEx, nil
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			iNdEx += length
			if length < 0 {
				return 0, ErrInvalidLengthRefs
			}
			return iNdEx, nil
		case 3:
			for {
				var innerWire uint64
				var start int = iNdEx
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return 0, ErrIntOverflowRefs
					}
					if iNdEx >= l {
						return 0, io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					innerWire |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				innerWireType := int(innerWire & 0x7)
				if innerWireType == 4 {
					break
				}
				next, err := skipRefs(dAtA[start:])
				if err != nil {
					return 0, err
				}
				iNdEx = start + next
			}
			return iNdEx, nil
		case 4:
			return iNdEx, nil
		case 5:
			iNdEx += 4
			return iNdEx, nil
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
	}
	panic("unreachable")
}

var (
	ErrInvalidLengthRefs = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowRefs   = fmt.Errorf("proto: integer overflow")
)

func init() { proto.RegisterFile("refs.proto", fileDescriptorRefs) }

var fileDescriptorRefs = []byte{
	// 517 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xb4, 0x92, 0x31, 0x6f, 0xd3, 0x40,
	0x14, 0xc7, 0x7b, 0x69, 0x52, 0x92, 0x33, 0x6d, 0x5d, 0x0b, 0xca, 0x35, 0xa0, 0x34, 0xca, 0x14,
	0x09, 0xc5, 0x86, 0x30, 0x50, 0x75, 0x40, 0x6a, 0xa1, 0x02, 0x44, 0x07, 0x64, 0x24, 0x18, 0x18,
	0x22, 0xdb, 0xb9, 0xb8, 0x56, 0x6c, 0xdf, 0xc9, 0x77, 0x2e, 0x64, 0xe3, 0xa3, 0xf0, 0x71, 0x32,
	0x32, 0x32, 0x21, 0xc8, 0xc4, 0x58, 0xa9, 0xfd, 0x00, 0xc8, 0xcf, 0x97, 0xd8, 0x6d, 0x88, 0xc4,
	0xc2, 0x62, 0xbd, 0xff, 0x7b, 0xff, 0xf7, 0xf7, 0xdd, 0xcf, 0xc6, 0x38, 0xa1, 0x23, 0x61, 0xf2,
	0x84, 0x49, 0x66, 0x34, 0xe8, 0xd0, 0xa7, 0x50, 0x36, 0x1f, 0xf8, 0x8c, 0xf9, 0x21, 0xb5, 0x1c,
	0x1e, 0x58, 0x4e, 0x1c, 0x33, 0xe9, 0xc8, 0x80, 0xc5, 0xca, 0xd8, 0x3c, 0xf0, 0x03, 0x79, 0x96,
	0xba, 0xa6, 0xc7, 0x22, 0x2b, 0x62, 0x6e, 0x10, 0x66, 0x8b, 0x9f, 0xad, 0xec, 0xd9, 0xf3, 0x42,
	0x96, 0x0e, 0x2d, 0xf0, 0xf9, 0x34, 0x5e, 0x14, 0x6a, 0xf3, 0xe5, 0xbf, 0x6d, 0x7a, 0x3d, 0x9f,
	0xc6, 0x3d, 0x2f, 0x9a, 0xcb, 0x52, 0xa1, 0x82, 0xb6, 0xc0, 0x1d, 0x52, 0xa9, 0xf4, 0xa6, 0x17,
	0xa6, 0x42, 0xd2, 0x44, 0xc9, 0x1d, 0x25, 0x83, 0x58, 0xcc, 0x1d, 0x0d, 0x87, 0x73, 0x55, 0xf6,
	0x4a, 0xa7, 0xf0, 0x99, 0xcf, 0xf2, 0x70, 0x37, 0x1d, 0x81, 0x02, 0x01, 0x55, 0x6e, 0xef, 0x5c,
	0x54, 0xf0, 0xed, 0xe7, 0xea, 0x75, 0x36, 0x1d, 0x09, 0xc3, 0xc4, 0xeb, 0x63, 0x3a, 0x21, 0xa8,
	0x8d, 0xba, 0x5a, 0x7f, 0xd7, 0x5c, 0x60, 0x33, 0xe7, 0xae, 0x37, 0x74, 0x72, 0x5c, 0x9d, 0xfe,
	0xd8, 0x5f, 0xb3, 0x33, 0xa3, 0xf1, 0x14, 0xd7, 0xd5, 0x79, 0x04, 0xa9, 0xb4, 0xd7, 0xbb, 0x5a,
	0xff, 0xee, 0xb5, 0x25, 0x18, 0x15, 0x3b, 0x0b, 0xb3, 0xb1, 0x87, 0xeb, 0xa9, 0xa0, 0xc3, 0x41,
	0xe2, 0x44, 0xa4, 0xda, 0x46, 0xdd, 0xaa, 0x7d, 0x2b, 0xd3, 0xb6, 0x13, 0x19, 0xfb, 0x58, 0x83,
	0xd1, 0xb9, 0xc7, 0x12, 0x2a, 0x48, 0x0d, 0xa6, 0x38, 0x6b, 0xbd, 0x87, 0x8e, 0x71, 0x1f, 0x37,
	0xc0, 0x30, 0x0c, 0xc4, 0x98, 0x6c, 0xc0, 0x18, 0xc2, 0x5e, 0x04, 0x62, 0x6c, 0x9c, 0xe2, 0xcd,
	0x84, 0x31, 0x39, 0x08, 0xdd, 0x01, 0x67, 0x89, 0x14, 0xa4, 0x0e, 0xc7, 0xea, 0xfe, 0xe5, 0x2e,
	0xd9, 0x8d, 0x4d, 0x9b, 0x31, 0x79, 0xea, 0xbe, 0xcd, 0xac, 0x27, 0xb1, 0x4c, 0x26, 0xb6, 0x96,
	0x14, 0x9d, 0xe6, 0x33, 0xac, 0xdf, 0x34, 0x18, 0x7a, 0xc1, 0xa8, 0x96, 0x53, 0xb8, 0x83, 0x6b,
	0xe7, 0x4e, 0x98, 0x52, 0x52, 0x81, 0x5e, 0x2e, 0x0e, 0x2b, 0x07, 0xe8, 0x50, 0xff, 0x7d, 0x49,
	0xd0, 0xc5, 0x25, 0x41, 0x5f, 0xae, 0x08, 0xfa, 0x7a, 0x45, 0x50, 0xe7, 0x3b, 0xc2, 0x9a, 0xe2,
	0x02, 0xc4, 0x1f, 0x97, 0x89, 0xef, 0x2d, 0xc3, 0x7b, 0x1d, 0x8b, 0x9b, 0xd0, 0x1f, 0xe2, 0xaa,
	0xc3, 0xf9, 0x1c, 0xf8, 0x4e, 0x69, 0xe7, 0x88, 0xf3, 0xc2, 0x0b, 0xa6, 0xff, 0x06, 0x7a, 0xf9,
	0x6a, 0xfd, 0x8f, 0x78, 0xbb, 0x8c, 0xf6, 0x88, 0x07, 0xc6, 0x2b, 0xac, 0xbf, 0x3b, 0x63, 0x9f,
	0xae, 0xfd, 0x63, 0xf7, 0x56, 0x7c, 0x8a, 0xe6, 0xaa, 0x41, 0x67, 0xed, 0x11, 0xea, 0x7f, 0xc0,
	0x5b, 0x25, 0x6c, 0x59, 0xf6, 0x09, 0xde, 0xce, 0xb3, 0x0b, 0x98, 0xbb, 0xcb, 0xfc, 0x20, 0x79,
	0x45, 0x3f, 0x0b, 0x3e, 0xd6, 0xa7, 0xbf, 0x5a, 0x6b, 0xd3, 0x59, 0x0b, 0x7d, 0x9b, 0xb5, 0xd0,
	0xcf, 0x59, 0x0b, 0xb9, 0x1b, 0x60, 0x7c, 0xf2, 0x27, 0x00, 0x00, 0xff, 0xff, 0x69, 0x05, 0x2b,
	0xcb, 0x42, 0x04, 0x00, 0x00,
}
